# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UkfweUzb_gnvy_ianh3EfwYbBPxB4NlJ
"""

import os
import numpy as np
import pandas as pd
import torch
from torch.utils.data import DataLoader, Dataset
from torchvision import models, transforms
from PIL import Image
import cv2
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import gdown
import zipfile

url = "https://drive.google.com/file/d/1ZTDQInkUPOFG5VCPF3rSsSuRtpwZMTCA/view?usp=drive_link"
output = "test_images.zip"
gdown.download(url, output, quiet=False, fuzzy=True)

def extract_images(zip_file_path, extract_to):
    if not os.path.exists(zip_file_path):
        print(f"Error: {zip_file_path} does not exist.")
        return
    if not os.path.exists(extract_to):
        os.makedirs(extract_to)
    try:
        with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
            for file in zip_ref.namelist():
                if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff')):
                    zip_ref.extract(file, extract_to)
                    print(f"Extracted: {file}")
            print(f"Images extracted to: {extract_to}")
    except zipfile.BadZipFile:
        print(f"Error: {zip_file_path} is not a valid zip file. It might be corrupted or incomplete.")

zip_file_path = "test_images.zip"
extract_to = "./test_images"
extract_images(zip_file_path, extract_to)

url = "https://drive.google.com/file/d/1kSSl4R16QtHC3GgnYEEUrpc102606XXu/view?usp=drive_link"
output = "model.pth"
gdown.download(url, output, quiet=False, fuzzy=True)

class HistogramEqualization:
    def __call__(self, img):
        image = np.array(img)
        if len(image.shape) == 3:
            channels = cv2.split(image)
            equalized_channels = [cv2.equalizeHist(channel) for channel in channels]
            equalized_image = cv2.merge(equalized_channels)
        else:
            equalized_image = cv2.equalizeHist(image)
            equalized_image = cv2.cvtColor(equalized_image, cv2.COLOR_GRAY2RGB)
        return Image.fromarray(equalized_image)

image_transforms = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    HistogramEqualization(),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

class TestDataset(Dataset):
    def __init__(self, directory, transform=None):
        self.directory = directory
        self.transform = transform
        self.image_paths = []
        self.labels = []
        for label, subdir in enumerate(["savory", "sweet"]):
            subdir_path = os.path.join(directory, subdir)
            for filename in os.listdir(subdir_path):
                if filename.endswith((".jpg", ".png")):
                    self.image_paths.append(os.path.join(subdir_path, filename))
                    self.labels.append(label)
    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        label = self.labels[idx]
        image = Image.open(img_path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, label, img_path

def predict(model, test_loader, device):
    model.eval()
    predictions = []
    true_labels = []
    with torch.no_grad():
        for inputs, labels, img_paths in test_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)
            outputs = model(inputs).squeeze(1)
            predicted_labels = (outputs >= 0.5).long()
            predicted_labels = predicted_labels.cpu().numpy()
            labels = labels.cpu().numpy()
            for i, img_path in enumerate(img_paths):
                predictions.append((img_path, predicted_labels[i]))
                true_labels.append(labels[i])
    return predictions, true_labels

model = models.resnet50(weights="IMAGENET1K_V1")
num_features = model.fc.in_features
model.fc = torch.nn.Sequential(
    torch.nn.Linear(num_features, 1),
    torch.nn.Sigmoid()
)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
model_weights_path = "model.pth"
model.load_state_dict(torch.load(model_weights_path, map_location=device))
model.eval()
print("Model weights loaded successfully!")

test_dataset = TestDataset("test_images", transform=image_transforms)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)

predictions, true_labels = predict(model, test_loader, device)

y_true = true_labels
y_pred = [pred[1] for pred in predictions]

accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred, average='binary')
recall = recall_score(y_true, y_pred, average='binary')
f1 = f1_score(y_true, y_pred, average='binary')
conf_matrix = confusion_matrix(y_true, y_pred)

print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1 Score: {f1:.4f}")
print("Confusion Matrix:")
print(conf_matrix)